name: Peter Duggins
email: psipeter@gmail.com
one_liner: Biologically detailed neuron models; Trust and social decision-making; Agent-based models
group: Grad students
title: PhD Student in Systems Design Engineering
picture: http://compneuro.uwaterloo.ca/files/peter_duggins_profile2.JPG

### Research

My driving purpose is to promote the wellbeing of intelligences that experience subjectively positive and negative states of consciousness. I believe the best way to realize this goal, for our species, is to simulate and analyze artificial societies populated with cognitively, emotionally, and socially plausible agents. My long-term research goals are oriented towards making this methodology scientifically plausible. To begin developing human-like AIs, I plan to (a) utilize the Neural Engineering Framework to specify how biological brains represent and process emotional and social information, (b) construct agents by incorporating emotional and social modules into SPAUN, and (c) generate unique personalities for these agents by exposing them to unique developmental regimes. With unlimited access to information in the simulation, I can (d) define quantitative measures of an agent's wellbeing based on its observed brain state. To maximize this quantity across an (e) artificial society composed of agents situated in a virtual environment, I will (f) design controlled experiments that investigate the personal and societal conditions which promote the greatest wellbeing, and finally (g) apply these results back to our reality for the same purpose.

In my masters thesis, I developed methods for incorporating biologically-detailed neuron models (such as those used in the Human Brain Project) into the NEF. I first showed that these methods may be used to instantiate numerous dynamical systems, including integrators, oscillators, and chaotic attractors, in neural networks, then used these systems to construct a neural model of working memory in which I simulated ADHD and its pharmacological treatments. It is my hope that these techniques can be used to simulate and study a wide range of biophysical mechanisms in the brain that were previously inaccessible with simple neuron models (i.e. LIF), as well as reduce our reliance on animal experiments and human trials when designing treatments for mental disorders. I also view this is as a necessary step in understanding the neuromodulatory control that emotional systems exert over other cognitive processes.

In my doctoral thesis, I study the relationship between trust and social decision-making. Social interaction is one of humanity's defining features: through it, humans develop ideas, express emotions, and form relationships. The brain's ability to facilitate these complex social and cognitive processes is at once astounding and mysterious. Many of the brain areas whose coordinated interaction give rise to language, trust, and empathy have been identified, and the importance of neurochemistry, functional connectivity, and developmental history have become increasingly apparent. However, the cognitive algorithms implemented within and between specific neural subsystems remain poorly understood: there exist few well-established theories describing what quantities each brain area represents, nor are there mechanistic models explaining how these areas interact to produce social behavior. My goal is to build a cognitive agent that exhibits human-like behavior in bounded social interactions using networks of biologically-plausible spiking neurons. The domain of choice will be a social game called the "trust game"; to play effectively, the agent must perform cognitive tasks that typify the challenges humans face in social interactions. The agent should balance selfish and social incentives, using rewards and punishments as guidance for future behavior. Furthermore, the agent should adapt its behavior to contextual information and in response to behaviors exhibited by its opponents. Finally, the agent should exhibit behavioral deficits aligned with human social dysfunctions when its brain-like cognitive architecture is perturbed neurally or pharmacologically. The successful implementation of such an agent would support high-level theories of social cognition, while the neural underpinnings of the agent would support low-level theories that explain how brains realize these computations given limited resources and training data.
